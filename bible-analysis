{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061253aa-7fd2-4b95-86ad-86fa53ef3221",
   "metadata": {},
   "source": [
    "## Import Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4602b3c6-6455-4b70-a272-44c8915f80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e89faf-133a-4b6b-ba66-4b380dad79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234500c4-3330-42a0-8015-a90df814f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_url = 'https://bereanbible.com/bsb.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1852a321-1553-45b1-a388-70ad2597cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bereanbible.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed67016-0a4a-4ae1-84d5-8930dda1955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(bible_url)\n",
    "raw_bible = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f78280-2122-49d5-a1c9-2f9bcfe64a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_list = raw_bible.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a1ad75-1c1f-4816-b1d4-fbb8f262e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_array = np.array([item.split('\\t') for item in bible_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07cab8e-3d38-4676-b5dd-2fa5835fd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_array[:, 1] = [item.replace('\\x93', '').replace('\\x94', '') for item in bible_array[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbf4160-f00b-4640-92a2-0048383a92c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Genesis 1:3',\n",
       "       'And God said, Let there be light, and there was light.'],\n",
       "      dtype='<U400')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_array[5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b56807a-d220-4fd8-baa8-256c9fd11914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bible_array = >>> best_string_ever = filter(lambda x: x in printable, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462b55bb-1ad0-4cb5-b270-893deafc6fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31105, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfb663fa-c050-4e92-b7f8-aa6860341f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bible_array[3:, :], columns=bible_array[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5abc1181-2c68-46c4-9473-7fba1a284422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "      <th>Berean Study Bible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis 1:1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis 1:2</td>\n",
       "      <td>Now the earth was formless and void, and darkn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis 1:3</td>\n",
       "      <td>And God said, Let there be light, and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis 1:4</td>\n",
       "      <td>And God saw that the light was good, and He se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis 1:5</td>\n",
       "      <td>God called the light day, and the darkness He ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Verse                                 Berean Study Bible\n",
       "0  Genesis 1:1  In the beginning God created the heavens and t...\n",
       "1  Genesis 1:2  Now the earth was formless and void, and darkn...\n",
       "2  Genesis 1:3  And God said, Let there be light, and there wa...\n",
       "3  Genesis 1:4  And God saw that the light was good, and He se...\n",
       "4  Genesis 1:5  God called the light day, and the darkness He ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8247e714-9761-4831-9430-c55e5d1629b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    4. Remove words\n",
    "    '''\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join([i for i in nopunc if not i.isdigit()])\n",
    "    nopunc = [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    return [stemmer.lemmatize(word) for word in nopunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a97c1d9b-948f-49f2-bd9c-dcd98a72a09b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'statement_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tfidfconvert \u001b[38;5;241m=\u001b[39m TfidfVectorizer(analyzer\u001b[38;5;241m=\u001b[39mtext_process)\u001b[38;5;241m.\u001b[39mfit(bible_array[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m transformed_statements \u001b[38;5;241m=\u001b[39m tfidfconvert\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mstatement_list\u001b[49m)\n\u001b[1;32m      3\u001b[0m df_vocab \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mzip\u001b[39m(tfidfconvert\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mkeys(),\n\u001b[1;32m      5\u001b[0m                                  tfidfconvert\u001b[38;5;241m.\u001b[39mvocabulary_\u001b[38;5;241m.\u001b[39mvalues()),\n\u001b[1;32m      6\u001b[0m                         columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m tfidf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(csr_matrix\u001b[38;5;241m.\u001b[39mtodense(transformed_statements), columns\u001b[38;5;241m=\u001b[39mdf_vocab\u001b[38;5;241m.\u001b[39mword)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'statement_list' is not defined"
     ]
    }
   ],
   "source": [
    "tfidfconvert = TfidfVectorizer(analyzer=text_process).fit(bible_array[:,1])\n",
    "transformed_statements = tfidfconvert.transform(statement_list)\n",
    "df_vocab = pd.DataFrame(index=None,\n",
    "                        data=zip(tfidfconvert.vocabulary_.keys(),\n",
    "                                 tfidfconvert.vocabulary_.values()),\n",
    "                        columns=['word', 'index']).sort_values('index')\n",
    "tfidf_df = pd.DataFrame(csr_matrix.todense(transformed_statements), columns=df_vocab.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c81edc-c1c5-4c2c-9286-0e2bff26216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41475495-5569-40b8-a6ef-7cf12851ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39:Python",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
